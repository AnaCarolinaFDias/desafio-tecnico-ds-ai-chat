{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import langchain\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configurar o logging para salvar a sa√≠da de debug em um arquivo\n",
    "logging.basicConfig(\n",
    "    filename='./logs/debug_output.log',  # O arquivo onde os logs ser√£o salvos\n",
    "    level=logging.DEBUG,          # O n√≠vel de log (DEBUG para capturar tudo)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Formato do log\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv() # read local .env file\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "   os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'inputs/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file, encoding=\"utf-8\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "\n",
    "split_documents = []\n",
    "for doc in docs:\n",
    "    split_docs = text_splitter.split_documents([doc])\n",
    "    split_documents.extend(split_docs)\n",
    "    \n",
    "    documents_dict = [\n",
    "    {\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in split_documents\n",
    "]\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open(\"inputs/documents_split_langchain.json\", \"w\") as file:\n",
    "    json.dump(documents_dict, file, indent=4)\n",
    "\n",
    "logger.debug(\"Documents have been saved to 'documents_split_langchain.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents split\n",
    "with open(\"inputs/documents_split_langchain.json\", \"r\") as file:\n",
    "    documents_dict = json.load(file)\n",
    "\n",
    "# Convert the list of dictionaries back to a list of Document objects\n",
    "documents = [\n",
    "    Document(page_content=doc[\"page_content\"], metadata=doc[\"metadata\"])\n",
    "    for doc in documents_dict\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable initialization\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"langchain_collection_OpenAI_embeddings\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"./langchain_collection\", \n",
    ")\n",
    "\n",
    "# Generate UUIDs for each document\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "# logger.debug(f'Generated UUIDs: {uuids[0]}...')  # Displaying the first 5 UUIDs for verification\n",
    "\n",
    "# Add documents in batches of 1000\n",
    "for i in range(0, len(documents), 1000):\n",
    "    logger.debug(f'Processing documents {i} to {min(i+1000, len(documents))}...')\n",
    "    \n",
    "    batch_documents = documents[i:i+1000]\n",
    "    batch_uuids = uuids[i:i+1000]\n",
    "    \n",
    "    # Log for each batch\n",
    "    logger.debug(f'Number of documents in the batch: {len(batch_documents)}')\n",
    "    \n",
    "    # Add documents to the vector store\n",
    "    try:\n",
    "        vector_store.add_documents(documents=batch_documents, ids=batch_uuids)\n",
    "        logger.info(f'Batch of documents {i} added successfully.')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error adding documents in batch {i}: {e}')\n",
    "\n",
    "logger.info(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import context_precision, context_recall, context_entity_recall\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import Document\n",
    "load_dotenv()\n",
    "\n",
    "queries = [\n",
    "    \"How can I import to use watsonx models?\",\n",
    "    \"How can I use SearchApi as part of a Self Ask chain?\",\n",
    "    \"How can I load a Wikipedia document?\",\n",
    "    \"How can I use a Wolfram alpha Tool?\",\n",
    "    \"Is ther any way to check the wheather?\",\n",
    "    \"Is there a way to use decorators?\",\n",
    "    \"Is the a way to use voice?\",\n",
    "    \"How to use Serper - Google Search API as part of a Self Ask chain?\",\n",
    "    \"What is Groq?\",\n",
    "    \"How to use Llama.cpp embeddings?\",\n",
    "    \"How to use GraphCypher?\",\n",
    "    \"How to build a knowledge graph from text?\",\n",
    "    \"What is Chroma?\",\n",
    "    \"What is Alchemy?\",\n",
    "    \"Is possible to use beautiful soap?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "  \"\"\"Install the integration package with pip install -qU langchain-ibm. Then get an IBM watsonx.ai api key and set it as an environment variable (`WATSONX_APIKEY`)\n",
    "  import os      \n",
    "  os.environ[\"WATSONX_APIKEY\"] = \"your IBM watsonx.ai api key\"  \n",
    "  Chat Model: from langchain_ibm import ChatWatsonx\n",
    "  \"\"\",\n",
    "  \n",
    "  \"\"\"from langchain_community.utilities import SearchApiAPIWrapper\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "import os\n",
    "os.environ[\"SEARCHAPI_API_KEY\"] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "llm = OpenAI(temperature=0)\n",
    "search = SearchApiAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"Who lived longer: Plato, Socrates, or Aristotle?\")\"\"\",\n",
    "\"\"\"Document Loader\n",
    "from langchain_community.document_loaders import WikipediaLoader\"\"\",\n",
    "\"\"\"Tool\n",
    "You can also easily load this wrapper as a Tool (to use with an Agent). You can do this with:\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "tools = load_tools([\"wolfram-alpha\"])\"\"\",\n",
    "\"\"\"OpenWeatherMap\n",
    "OpenWeatherMap provides all essential weather data for a specific location:\n",
    "\n",
    "Current weather\n",
    "Minute forecast for 1 hour\n",
    "Hourly forecast for 48 hours\n",
    "Daily forecast for 8 days\n",
    "National weather alerts\n",
    "Historical weather data for 40+ years back\"\"\",\n",
    "\"\"\"LangChain decorators is a layer on the top of LangChain that provides syntactic sugar üç≠ for writing custom langchain prompts and chains\"\"\",\n",
    "\"\"\"ElevenLabs is a voice AI research & deployment company with a mission to make content universally accessible in any language & voice.\n",
    "ElevenLabs creates the most realistic, versatile and contextually-aware AI audio, providing the ability to generate speech in hundreds of new and existing voices in 29 languages.\"\"\",\n",
    "\"\"\"from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")\"\"\",\n",
    "\"\"\"Welcome to Groq! üöÄ At Groq, we've developed the world's first Language Processing Unit‚Ñ¢, or LPU. The Groq LPU has a deterministic, single core streaming architecture that sets the standard for GenAI inference speed with predictable and repeatable performance for any given workload.\n",
    "\n",
    "Beyond the architecture, our software is designed to empower developers like you with the tools you need to create innovative, powerful AI applications. With Groq as your engine, you can:\n",
    "\n",
    "Achieve uncompromised low latency and performance for real-time AI and HPC inferences üî•\n",
    "Know the exact performance and compute time for any given workload üîÆ\n",
    "Take advantage of our cutting-edge technology to stay ahead of the competition üí™\"\"\",\n",
    "\"\"\"Embeddings\n",
    "There exists a LlamaCpp Embeddings wrapper, which you can access with\n",
    "\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\"\"\",\n",
    "\"\"\"There exists a wrapper around Neo4j graph database that allows you to generate Cypher statements based on the user input and use them to retrieve relevant information from the database.\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\"\"\",\n",
    "\"\"\"Constructing a knowledge graph from text\n",
    "Text data often contain rich relationships and insights that can be useful for various analytics, recommendation engines, or knowledge management applications. Diffbot's NLP API allows for the extraction of entities, relationships, and semantic meaning from unstructured text data. By coupling Diffbot's NLP API with Neo4j, a graph database, you can create powerful, dynamic graph structures based on the information extracted from text. These graph structures are fully queryable and can be integrated into various applications.\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers.diffbot import DiffbotGraphTransformer\"\"\",\n",
    "\"\"\"Chroma is a database for building AI applications with embeddings.\"\"\",\n",
    "\"\"\"Alchemy is the platform to build blockchain applications.\"\"\",\n",
    "\"\"\"Installation and Setup\n",
    "pip install beautifulsoup4\n",
    "Document Transformer\n",
    "from langchain_community.document_loaders import BeautifulSoupTransformer\"\"\"\n",
    "]\n",
    "def validation_embeddings(queries, ground_truths, embeddings_provider):\n",
    "    \n",
    "    # Load the list of dictionaries from the JSON file\n",
    "    with open(f\"results/query_{embeddings_provider}_results.json\", \"r\") as file:\n",
    "        documents_dict = json.load(file)\n",
    "\n",
    "    # Convert the list of dictionaries back to a list of Document objects\n",
    "    documents = [\n",
    "        [Document(page_content=result[\"page_content\"], metadata=result[\"metadata\"])for result in doc]\n",
    "        for doc in documents_dict\n",
    "    ]\n",
    "    results_page_contents = [[doc.page_content for doc in sublist] for sublist in documents]\n",
    "\n",
    "    d = {\n",
    "        \"question\": queries,\n",
    "        #\"answer\": results,\n",
    "        \"contexts\": results_page_contents,\n",
    "        \"ground_truth\": ground_truths\n",
    "    }\n",
    "\n",
    "    dataset = Dataset.from_dict(d)\n",
    "    #score = evaluate(dataset, metrics=[faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness, harmfulness])\n",
    "    score = evaluate(dataset, metrics=[context_precision, context_recall, context_entity_recall])\n",
    "    print(score)\n",
    "    score_df = score.to_pandas()\n",
    "    score_df.to_parquet(f'./results/results_{embeddings_provider}_embeddings_split.parquet')\n",
    "    print(f'results/results_{embeddings_provider}_embeddings_split.parquet generated')\n",
    "\n",
    "print(\"starting HF validation:\")\n",
    "validation_embeddings(queries, ground_truths, 'HF')\n",
    "print(\"starting Google validation:\")\n",
    "validation_embeddings(queries, ground_truths, 'Google')\n",
    "print(\"starting OpenAI validation:\")\n",
    "validation_embeddings(queries, ground_truths, 'OpenAI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
